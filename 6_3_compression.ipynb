{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 (a) \n",
    "_Create a long random string using a Python program, and use a lossless compression algorithm of your choice to compress the string. Note the compression ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import zlib\n",
    "import gzip\n",
    "import bz2 # bzip\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create_rand_str is a lambda function that creates a rand string of len n chars\n",
    "create_rand_str = lambda n: ''.join(random.choices(string.ascii_letters, k=n)) \n",
    "\n",
    "rand_long_str = create_rand_str(1000000000) # Generate random string with n=1000000000 chars\n",
    "\n",
    "long_rand_variable = rand_long_str.encode() # Need to encode to bytes for compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed Size: 1000000033 bytes\n"
     ]
    }
   ],
   "source": [
    "# long_rand_variable must be in bytes\n",
    "encoded_rand_long_str_size = sys.getsizeof(long_rand_variable)\n",
    "print(f'Uncompressed Size: {encoded_rand_long_str_size} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Size: 728308808 bytes\n",
      "Compression ratio zlib 1.373 bits/bit\n"
     ]
    }
   ],
   "source": [
    "encoded_compressed_str = zlib.compress(long_rand_variable)\n",
    "encoded_compressed_str_size = sys.getsizeof(encoded_compressed_str)\n",
    "print(f'Compressed Size: {encoded_compressed_str_size} bytes')\n",
    "compression_ratio = encoded_rand_long_str_size/encoded_compressed_str_size\n",
    "\n",
    "print(f'Compression ratio zlib {compression_ratio:.3f} bits/bit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Size: 728308820 bytes\n",
      "Compression ratio gzip 1.373 bits/bit\n"
     ]
    }
   ],
   "source": [
    "encoded_compressed_str = gzip.compress(long_rand_variable)\n",
    "encoded_compressed_str_size = sys.getsizeof(encoded_compressed_str)\n",
    "print(f'Compressed Size: {encoded_compressed_str_size} bytes')\n",
    "\n",
    "compression_ratio = encoded_rand_long_str_size/encoded_compressed_str_size\n",
    "\n",
    "print(f'Compression ratio gzip {compression_ratio:.3f} bits/bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Size: 721162869 bytes\n",
      "Compression ratio bzip 1.387 bits/bit\n"
     ]
    }
   ],
   "source": [
    "encoded_compressed_str = bz2.compress(long_rand_variable)\n",
    "encoded_compressed_str_size = sys.getsizeof(encoded_compressed_str)\n",
    "print(f'Compressed Size: {encoded_compressed_str_size} bytes')\n",
    "\n",
    "compression_ratio = encoded_rand_long_str_size/encoded_compressed_str_size\n",
    "\n",
    "print(f'Compression ratio bzip {compression_ratio:.3f} bits/bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Conclusion:\n",
    "Despite generating random source (a string with random chars), we are still able to compress the data with a compression ratio **G â‰ˆ 1.38 bits/bit** regardless of the compression algorithm used (zlib, gzip, bz2).\n",
    "\n",
    "The ratio of 1.38 bits/bit on a random source signifies that we could pretty much do a 80/20 training/test split and achieve high accuracy, despite not learning any underlying function (since no underlying function exists for a random source)\n",
    "\n",
    "In short, just because we can compress it, doesn't mean we can learn it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 (b)\n",
    "_What is the expected compression ratio in (a)? Explain why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Answer:\n",
    "The **expected compression ratio in (a) is 2 bits/bit**. In other terms a 2:1 compression ratio is the theoretical limit because as n -> infinity, we can almost guarantee to memorize 2 points per parameter (MacKay 2003). This phenomenon was as demonstrated in 6.1, were we experimentally proved Definition 5.1\n",
    "\n",
    "In the 6.3 (a) experiment, as we increase the length of the random string (n) the compression ratio increases from around 1.1 -> 1.3.\n",
    "Theoretically as n -> infinity, the compression ratio will approach 2, since we can memorize 2 points per parameter, which would provide a 2:1 compression ratio.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
