{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_equal_classes(n_full, num_classes):\n",
    "    if n_full % num_classes != 0:\n",
    "        raise ValueError(\"n_full is not evenly divisible by num_classes\")\n",
    "    \n",
    "    # Number of instances per class\n",
    "    n_per_class = n_full // num_classes\n",
    "    \n",
    "    # Generate and shuffle array\n",
    "    classes = np.concatenate([np.full(n_per_class, i) for i in range(num_classes)])\n",
    "    np.random.shuffle(classes)\n",
    "    \n",
    "    return classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_memorized_points(X, y):\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    n_memorized = 0\n",
    "    n_full = len(y)\n",
    "    for i in range(n_full):\n",
    "        # Delete the row and y\n",
    "        X_train = np.delete(X, i, axis=0)\n",
    "        y_train = np.delete(y, i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        # Test if deleted y is still predicted correctly\n",
    "        if knn.predict([X[i]]) == y[i]:\n",
    "            # If y is predicted correctly, despite dropping the row, then that row was redundant\n",
    "            n_memorized += 1 # Increment the count of redundant training points\n",
    "\n",
    "    return n_full - n_memorized # removing the redundant points, leaves the kept 'necessary' rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I use Alg 8 to count thresholds and test accuracy\n",
    "# Note this is purely out of curiosity and not nessicary for 6.1\n",
    "def count_thresholds(X, y):\n",
    "    # Note that Alg 8 assumes a perfect ML model\n",
    "    thresholds = 0\n",
    "\n",
    "    sum_table = [(sum(row), label) for row, label in zip(X, y)] # Sum x rows\n",
    "    sorted_table = sorted(sum_table, key=lambda x: x[0]) # Sort by increasing x\n",
    "\n",
    "    needed_x = []\n",
    "    needed_y = []\n",
    "\n",
    "    current_class = sorted_table[0][1] # Start by setting current_class, to the class of the first row\n",
    "    for row, row_class in sorted_table:\n",
    "        # If the sign changes, then that row is 'necessary', hence thresholds is incremented\n",
    "        if row_class != current_class:\n",
    "            current_class = row_class\n",
    "            thresholds += 1\n",
    "        # else: # Doing it this way gives better results, probably because its including more rows\n",
    "            needed_x.append([row]) \n",
    "            needed_y.append(row_class)\n",
    "             \n",
    "    sorted_x, sorted_y = zip(*sorted_table)\n",
    "    sorted_x_arr = []\n",
    "\n",
    "    for row in sorted_x:\n",
    "        sorted_x_arr.append([row])\n",
    "    sorted_y = list(sorted_y) \n",
    "\n",
    "    # Now test the 'needed' rows against the entire sorted table\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(needed_x, needed_y)\n",
    "    y_pred = knn.predict(sorted_x_arr) # test on full\n",
    "    accuracy = accuracy_score(sorted_y, y_pred)\n",
    "    # print(f'    Accuracy = {accuracy}, y_needed = {needed_y}')\n",
    "    \n",
    "    return thresholds, sorted_x_arr, sorted_y, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(D: int, n_full: int, num_classes):\n",
    "    n_mem_count = 0\n",
    "    n_mem_count_1D = 0\n",
    "    n_thresholds = 0\n",
    "    n_alg_8_acc = 0\n",
    "    \n",
    "    n_experiments = 50\n",
    "    for i in range(n_experiments):\n",
    "        X = np.random.rand(n_full, D)\n",
    "        \n",
    "        # I tested with both random y and y with equal number of 1's and 0's\n",
    "        # y = np.random.randint(0, 2, size=n_full)\n",
    "        y = generate_equal_classes(n_full, num_classes)\n",
    "\n",
    "        thresholds, sorted_x, sorted_y, alg_8_acc = count_thresholds(X, y)\n",
    "        n_thresholds += thresholds\n",
    "        n_alg_8_acc += alg_8_acc\n",
    "\n",
    "        n_mem_count_1D += count_memorized_points(sorted_x, sorted_y)\n",
    "        n_mem_count += count_memorized_points(X, y)\n",
    "\n",
    "    # Calculate all the averages\n",
    "    n_avg_1D = n_mem_count_1D/n_experiments\n",
    "    n_avg = n_mem_count/n_experiments\n",
    "    avg_thresholds = n_thresholds/n_experiments\n",
    "    avg_alg_8_acc = n_alg_8_acc/n_experiments\n",
    "\n",
    "    base = f\"Base Results: d={D}: n_full={n_full}, Avg. req. points for memorization n_avg={n_avg:.2f}, n_full/n_avg={n_full/n_avg}\"\n",
    "    row_sum = f\"Rows Sum Results: d={D}: n_full={n_full}, Avg. req. points for memorization n_avg={n_avg_1D:.2f}, n_full/n_avg={n_full/n_avg_1D} \"\n",
    "    thresh = f\"Threshold Results: d={D}: n_full={n_full}, Avg. Thresh={avg_thresholds}, Avg. Alg_8 Accuracy={avg_alg_8_acc}, n_full/thresh_avg={n_full/avg_thresholds}\"\n",
    "    return base, row_sum, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "**Only the Base Results are required for 6.1**  \n",
    "The additional results in _Findings from the Algorithm 8_ (Rows Sum Result and Threshold Results) were merely for my own exploration of Algorithm 8 on page 118. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Results: d=2: n_full=4, Avg. req. points for memorization n_avg=4.00, n_full/n_avg=1.0\n",
      "Base Results: d=4: n_full=16, Avg. req. points for memorization n_avg=13.08, n_full/n_avg=1.2232415902140672\n",
      "Base Results: d=8: n_full=256, Avg. req. points for memorization n_avg=193.20, n_full/n_avg=1.3250517598343685\n",
      "Base Results: d=16: n_full=1024, Avg. req. points for memorization n_avg=771.04, n_full/n_avg=1.3280763643909526\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(64)\n",
    "# All experiments are being tested with 4 classes\n",
    "# Since 6.2 is a multi-class dataset, I use num_classes = 4\n",
    "results = {}\n",
    "results['2D'] = run_experiment(D=2, n_full=4, num_classes=4)\n",
    "print(results['2D'][0])\n",
    "\n",
    "results['4D'] = run_experiment(D=4, n_full=16, num_classes=4)\n",
    "print(results['4D'][0])\n",
    "\n",
    "results['8D'] = run_experiment(D=8, n_full=256, num_classes=4)\n",
    "print(results['8D'][0])\n",
    "\n",
    "results['16D'] = run_experiment(D=16, n_full=1024, num_classes=4)\n",
    "print(results['16D'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Examining the Base Results:\n",
    "The base results are done with the _count_memorized_points_ function that drops rows that do not negatively impact accuracy.\n",
    "You can see that as the dimensions (D) increase n_full/n_avg approaches 2.\n",
    "\n",
    "- D=2, n_full/n_avg = 1.0\n",
    "- D=4, n_full/n_avg = 1.2232415902140672\n",
    "- D=8, n_full/n_avg = 1.3250517598343685\n",
    "- D=16, n_full/n_avg = 1.3280763643909526\n",
    "\n",
    "_Results are from code block above using rand seed of 64_\n",
    "\n",
    "#### Theoretical Information Capacity:\n",
    "\n",
    "_Definition 5.1_ Information Capacity of a linear Separator C = c/(c-1)\n",
    "- 4 classes -> c = 4\n",
    "- **C = 4/(4-1) = 1.3334**\n",
    "\n",
    "Therefore our **experimental results** align with the **theoretical calculation**\n",
    "\n",
    "Note: This theoretical result is also achieved using the threshold counting theorem form Algorithm 8 (see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings from the Algorithm 8:\n",
    "Algorithm 8 requires two _data prep_ steps: 1. Summing the x rows. 2. Sorting the table by increasing x.  \n",
    "Once the Data is prepared, then you iterate through the new table increment thresholds every time the class (y) changes.\n",
    "- I wanted to test the _count_memorized_points_ function, on the prepared data table as outlined in Algorithm 8. The results of this test are the **'Rows Sum Results'**\n",
    "- Below you can see that summing and sorting the data has _negligible effect_ on the n_full/n_avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Sum Results: d=2: n_full=4, Avg. req. points for memorization n_avg=4.00, n_full/n_avg=1.0 \n",
      "Rows Sum Results: d=4: n_full=16, Avg. req. points for memorization n_avg=13.08, n_full/n_avg=1.2232415902140672 \n",
      "Rows Sum Results: d=8: n_full=256, Avg. req. points for memorization n_avg=193.12, n_full/n_avg=1.3256006628003314 \n",
      "Rows Sum Results: d=16: n_full=1024, Avg. req. points for memorization n_avg=768.48, n_full/n_avg=1.3325005205080158 \n"
     ]
    }
   ],
   "source": [
    "# Print the Experimental Results with the summed and sorted table from Alg 8\n",
    "print(results['2D'][1])\n",
    "print(results['4D'][1])\n",
    "print(results['8D'][1])\n",
    "print(results['16D'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Counting Thresholds\n",
    "Continuing to implement the threshold increment part of Algorithm 8 I decided to test a KNN on only rows that increased the threshold:\n",
    "- In this test I began to notice that the **average threshold count was getting very close to n_avg** as the D increased. \n",
    "- Therefore I decided to record n_full/thresh_avg, which stays around 1.334, regardless of the dimensions. \n",
    "    - Having n_full/thresh_avg ≈ 1.334 Demonstrates that the **Theoretical upper limit** for n_full/n_avg to be 1.334 for classification with 4 classes\n",
    "- An additional interesting find was that **as D increases, the Accuracy** of training a KNN on **just** the threshold rows (Alg_8 Accuracy), increased with dimensions (D):\n",
    "    - D=2, Avg. Alg_8 Accuracy = 0.75\n",
    "    - D=4, Avg. Alg_8 Accuracy = 0.855\n",
    "    - D=8, Avg. Alg_8 Accuracy = 0.873125\n",
    "    - D=16 Abg. Alg_8 Accuracy = 0.87453125\n",
    "\n",
    "\n",
    "_Alg_8 Accuracy values are displayed by the output of the codeblock below_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold Results: d=2: n_full=4, Avg. Thresh=3.0, Avg. Alg_8 Accuracy=0.75, n_full/thresh_avg=1.3333333333333333\n",
      "Threshold Results: d=4: n_full=16, Avg. Thresh=12.32, Avg. Alg_8 Accuracy=0.855, n_full/thresh_avg=1.2987012987012987\n",
      "Threshold Results: d=8: n_full=256, Avg. Thresh=192.44, Avg. Alg_8 Accuracy=0.873125, n_full/thresh_avg=1.3302847640823114\n",
      "Threshold Results: d=16: n_full=1024, Avg. Thresh=767.68, Avg. Alg_8 Accuracy=0.87453125, n_full/thresh_avg=1.3338891204668613\n"
     ]
    }
   ],
   "source": [
    "# Print the Results from counting thresholds with the summed and sorted table from Alg 8\n",
    "print(results['2D'][2])\n",
    "print(results['4D'][2])\n",
    "print(results['8D'][2])\n",
    "print(results['16D'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "In conclusion, I used KNN to Empirically show that the information capacity limit approaches 2 prediction bits per parameter as the dimensionality (D) Increases\n",
    "\n",
    "To show this I did the following steps:\n",
    "1. Make a table of d dimensions and n rows, populated the x with random noise and Y with **4 classes** of equal distribution.\n",
    "2. Crated a _count_memorized_points_ function that iteratively drops rows from the table, and tests if the accuracy drops.\n",
    "3. Did 50 experiment runs per D and averaged the _count_memorized_points_ results into n_avg. \n",
    "4. Test the following configurations (D=2, n_full=4), (D=4, n_full=16), (D=8, n_full=256)\n",
    "5. Observed that as dimensionality (D) increases, n_full/n_avg approaches 2.\n",
    "\n",
    "\n",
    "\n",
    "Finally out of my own curiosity I implemented parts of Algorithm 8 to enhance my understanding of the larger lesson  \n",
    "Implementing Algorithm 8 showed:\n",
    " - That for Classification of 4 classes, the theoretical upper limit is n_full/n_avg ≈ 1.33 (This matches the Information Capacity C calculation)\n",
    " - Training on rows that increment the threshold increases accuracy with dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
